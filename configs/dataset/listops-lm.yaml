_name_: listops_lm
l_max: 2048
append_bos: False
append_eos: True
n_workers: 4 # Only used for tokenizing once
max_vocab: 20 # Actual size 18
# __train_len: 96000
__l_max: ${.l_max}

# Language modeling params - doesn't exist in source dataset
sequential: True
mlm_prob: 0.0  # self pre-training : prob of masking out a pixel
causal_lm: False  # self pre-training : predict next pixel in sequence
lm_loss: ce  # self pre-training loss: cross-entropy (ce) or l1
ignore_val: True  # ignore the loss at masked pixels
span_masking: False
span_length: 0
nesting_lvl: False
